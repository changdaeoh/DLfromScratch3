{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 52. supporting GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cupy 설치 및 사용\n",
    "* gpu를 이용해 모든 계산 수행\n",
    "* numpy와 API가 거의 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "x = cp.arange(6).reshape(2,3)\n",
    "print(x)\n",
    "\n",
    "y = x.sum(axis = 1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = np.array([1,2,3])\n",
    "c = cp.asarray(n)\n",
    "assert type(c) == cp.ndarray\n",
    "\n",
    "c = cp.array([1,2,3])\n",
    "n = cp.asnumpy(c)\n",
    "assert type(n) == np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/changdaeoh/DeepLearning-from-scratch/blob/main/images/52_note1.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x가 numpy 배열인경우\n",
    "x = np.array([1,2,3])\n",
    "xp = cp.get_array_module(x)    \n",
    "assert xp == np\n",
    "\n",
    "# x가 cupy 배열인경우\n",
    "x = cp.array([1,2,3])\n",
    "xp = cp.get_array_module(x)\n",
    "assert xp == cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cp.get_array_module(x)`\n",
    ": input받은 배열이 속하는 모듈을 알아서 판단하여 반환한다.(np or cp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variable 클래스를 아래와 같이 수정한다.\n",
    "* input 데이터 type으로 numpy array외에 cupy array도 지원한다.\n",
    "* 흐르는 데이터로부터 알아서 적합한 모듈(np, cp)을 찾아 대응 함수를 적용시키도록 메서드들을 수정\n",
    "* 데이터를 cpu <-> gpu 전송 가능하게하는 메서드를 추가u 전송 가능하게하는 메서드를 추가\n",
    "\n",
    "모든 np. 로 시작하는 코드를 xp로 수정 (데이터로부터 적절한 모듈을 선택하도록)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import dezero\n",
    "import dezero.functions as F\n",
    "from dezero import optimizers\n",
    "from dezero import DataLoader\n",
    "from dezero.models import MLP\n",
    "\n",
    "\n",
    "max_epoch = 5\n",
    "batch_size = 100\n",
    "\n",
    "train_set = dezero.datasets.MNIST(train=True)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "model = MLP((1000, 10))\n",
    "optimizer = optimizers.SGD().setup(model)\n",
    "\n",
    "# GPU mode\n",
    "if dezero.cuda.gpu_enable:\n",
    "    train_loader.to_gpu()\n",
    "    model.to_gpu()\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    start = time.time()\n",
    "    sum_loss = 0\n",
    "\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "\n",
    "    elapsed_time = time.time() - start\n",
    "    print('epoch: {}, loss: {:.4f}, time: {:.4f}[sec]'.format(\n",
    "        epoch + 1, sum_loss / len(train_set), elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 53. load & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\study\\\\DLfromScratch3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[1 2 3]\n",
      "[4 5 6]\n",
      "[1 2 3]\n",
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# save, savez, load function\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "np.save('test.npy', x)\n",
    "\n",
    "y = np.load('test.npy')\n",
    "print(y)\n",
    "\n",
    "x1 = np.array([1,2,3])\n",
    "x2 = np.array([4,5,6])\n",
    "np.savez('test.npz', x1 = x1, x2 = x2) # 키워드 지정\n",
    "\n",
    "arrays = np.load('test.npz')\n",
    "x1 = arrays['x1']\n",
    "x2 = arrays['x2']\n",
    "print(x1); print(x2)\n",
    "\n",
    "x1 = np.array([1,2,3])\n",
    "x2 = np.array([4,5,6])\n",
    "data = {'x1':x1, 'x2':x2}\n",
    "np.savez('test2.npz', **data) \n",
    "\n",
    "arrays = np.load('test2.npz')\n",
    "x1 = arrays['x1']\n",
    "x2 = arrays['x2']\n",
    "print(x1); print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 클래스에 추가\n",
    "def _flatten_params(self, params_dict, parent_key = \"\"):\n",
    "    for name in self._params:\n",
    "        obj = self.__dict__[name]\n",
    "        key = parent_key + '/' + name if parent_key else name\n",
    "            \n",
    "        if isinstance(obj, Layer):\n",
    "            obj._flatten_params(params_dict, key)\n",
    "        else:\n",
    "            params_dict[key] = obj\n",
    "    \n",
    "def save_weights(self, path):\n",
    "    self.to_cpu()\n",
    "\n",
    "    params_dict = {}\n",
    "    self._flatten_params(params_dict)\n",
    "    array_dict = {key: param.data for key, param in params_dict.items()\n",
    "                    if param is not None}\n",
    "    try:\n",
    "        np.savez_compressed(path, **array_dict)\n",
    "    except (Exception, KeyboardInterrupt) as e:\n",
    "        if os.path.exists(path):\n",
    "             os.remove(path)\n",
    "        raise\n",
    "\n",
    "def load_weights(self, path):\n",
    "    npz = np.load(path)\n",
    "    params_dict = {}\n",
    "    self._flatten_params(params_dict)\n",
    "    for key, param in params_dict.items():\n",
    "            param.data = npz[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in globals():\n",
    "    import os, sys\n",
    "    sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "import dezero\n",
    "import dezero.functions as F\n",
    "from dezero import optimizers\n",
    "from dezero import DataLoader\n",
    "from dezero.models import MLP\n",
    "\n",
    "\n",
    "max_epoch = 3\n",
    "batch_size = 100\n",
    "\n",
    "train_set = dezero.datasets.MNIST(train=True)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "model = MLP((1000, 10))\n",
    "optimizer = optimizers.SGD().setup(model)\n",
    "\n",
    "if os.path.exists('my_mlp.npz'):\n",
    "    model.load_weights('my_mlp.npz')\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    sum_loss = 0\n",
    "\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "\n",
    "    print('epoch: {}, loss: {:.4f}'.format(\n",
    "        epoch + 1, sum_loss / len(train_set)))\n",
    "\n",
    "model.save_weights('my_mlp.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 54. dropout & test mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 과대적합 원인 및 해결\n",
    "* 훈련 데이터 부족 -> 데이터 증강(data augmentation)\n",
    "* 모델 표현력이 지나치게 높음 -> 가중치 감소(Weight Decay), 드롭아웃(Dropout), 배치 정규화(Batch Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dropout_ratio = 0.6\n",
    "x = np.ones(10)\n",
    "\n",
    "# dropout의 train단계에서의 behavior\n",
    "# 데이터를 흘려보낼 때마다 선별적 비활성화\n",
    "mask = np.random.rand(10) > dropout_ratio # 1, 0 masking vector\n",
    "y = x * mask \n",
    "\n",
    "# test mode에서의 행동\n",
    "# 일단 모든 뉴런을 사용하여 결과를 계산하고 그 결과를 '약화'시킨다.\n",
    "scale = 1 - dropout_ratio # 학습 시 살아남은 뉴런의 비율\n",
    "y = x * scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inverted Dropout\n",
    "> 학습단계에서 뉴런 출력조절을 미리 수행. <br/>\n",
    "테스트 시에는 아무런 동작도 하지 않음 (테스트 속도가 살짝 향상됨)<br/>\n",
    "드롭아웃 비율을 학습 시 동적으로 제어할 수 있다는 장점이 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시\n",
    "scale = 1 - dropout_ratio\n",
    "mask = np.random.rand(*x.shape) > dropout_ratio\n",
    "y = x * mask / scale\n",
    "\n",
    "# 테스트 시\n",
    "y = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(x, dropout_ratio=0.5):\n",
    "    x = as_variable(x)\n",
    "\n",
    "    if dezero.Config.train:\n",
    "        xp = cuda.get_array_module(x)\n",
    "        mask = xp.random.rand(*x.shape) > dropout_ratio\n",
    "        scale = xp.array(1.0 - dropout_ratio).astype(x.dtype)\n",
    "        y = x * mask / scale\n",
    "        return y\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "variable([2. 2. 0. 2. 0.])\n",
      "variable([1. 1. 1. 1. 1.])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dezero import test_mode\n",
    "import dezero.functions as F\n",
    "\n",
    "x = np.ones(5)\n",
    "print(x)\n",
    "\n",
    "# 학습\n",
    "y = F.dropout(x)\n",
    "print(y) # 남은 뉴런들의 출력 뻥튀기 1/(1 - dropout_ratio) 배\n",
    "\n",
    "# 추론\n",
    "with test_mode():\n",
    "    y = F.dropout(x)\n",
    "    print(y) # 아무런 동작(마스킹이나 스케일링)도 하지 않고 그대로 흘려보냄"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
