{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 52. supporting GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cupy 설치 및 사용\n",
    "* gpu를 이용해 모든 계산 수행\n",
    "* numpy와 API가 거의 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "x = cp.arange(6).reshape(2,3)\n",
    "print(x)\n",
    "\n",
    "y = x.sum(axis = 1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = np.array([1,2,3])\n",
    "c = cp.asarray(n)\n",
    "assert type(c) == cp.ndarray\n",
    "\n",
    "c = cp.array([1,2,3])\n",
    "n = cp.asnumpy(c)\n",
    "assert type(n) == np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/changdaeoh/DeepLearning-from-scratch/blob/main/images/52_note1.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x가 numpy 배열인경우\n",
    "x = np.array([1,2,3])\n",
    "xp = cp.get_array_module(x)    \n",
    "assert xp == np\n",
    "\n",
    "# x가 cupy 배열인경우\n",
    "x = cp.array([1,2,3])\n",
    "xp = cp.get_array_module(x)\n",
    "assert xp == cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cp.get_array_module(x)`\n",
    ": input받은 배열이 속하는 모듈을 알아서 판단하여 반환한다.(np or cp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variable 클래스를 아래와 같이 수정한다.\n",
    "* input 데이터 type으로 numpy array외에 cupy array도 지원한다.\n",
    "* 흐르는 데이터로부터 알아서 적합한 모듈(np, cp)을 찾아 대응 함수를 적용시키도록 메서드들을 수정\n",
    "* 데이터를 cpu <-> gpu 전송 가능하게하는 메서드를 추가u 전송 가능하게하는 메서드를 추가\n",
    "\n",
    "모든 np. 로 시작하는 코드를 xp로 수정 (데이터로부터 적절한 모듈을 선택하도록)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import dezero\n",
    "import dezero.functions as F\n",
    "from dezero import optimizers\n",
    "from dezero import DataLoader\n",
    "from dezero.models import MLP\n",
    "\n",
    "\n",
    "max_epoch = 5\n",
    "batch_size = 100\n",
    "\n",
    "train_set = dezero.datasets.MNIST(train=True)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "model = MLP((1000, 10))\n",
    "optimizer = optimizers.SGD().setup(model)\n",
    "\n",
    "# GPU mode\n",
    "if dezero.cuda.gpu_enable:\n",
    "    train_loader.to_gpu()\n",
    "    model.to_gpu()\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    start = time.time()\n",
    "    sum_loss = 0\n",
    "\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "\n",
    "    elapsed_time = time.time() - start\n",
    "    print('epoch: {}, loss: {:.4f}, time: {:.4f}[sec]'.format(\n",
    "        epoch + 1, sum_loss / len(train_set), elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 53. load & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\study\\\\DLfromScratch3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[1 2 3]\n",
      "[4 5 6]\n",
      "[1 2 3]\n",
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# save, savez, load function\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "np.save('test.npy', x)\n",
    "\n",
    "y = np.load('test.npy')\n",
    "print(y)\n",
    "\n",
    "x1 = np.array([1,2,3])\n",
    "x2 = np.array([4,5,6])\n",
    "np.savez('test.npz', x1 = x1, x2 = x2) # 키워드 지정\n",
    "\n",
    "arrays = np.load('test.npz')\n",
    "x1 = arrays['x1']\n",
    "x2 = arrays['x2']\n",
    "print(x1); print(x2)\n",
    "\n",
    "x1 = np.array([1,2,3])\n",
    "x2 = np.array([4,5,6])\n",
    "data = {'x1':x1, 'x2':x2}\n",
    "np.savez('test2.npz', **data) \n",
    "\n",
    "arrays = np.load('test2.npz')\n",
    "x1 = arrays['x1']\n",
    "x2 = arrays['x2']\n",
    "print(x1); print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 클래스에 추가\n",
    "def _flatten_params(self, params_dict, parent_key = \"\"):\n",
    "    for name in self._params:\n",
    "        obj = self.__dict__[name]\n",
    "        key = parent_key + '/' + name if parent_key else name\n",
    "            \n",
    "        if isinstance(obj, Layer):\n",
    "            obj._flatten_params(params_dict, key)\n",
    "        else:\n",
    "            params_dict[key] = obj\n",
    "    \n",
    "def save_weights(self, path):\n",
    "    self.to_cpu()\n",
    "\n",
    "    params_dict = {}\n",
    "    self._flatten_params(params_dict)\n",
    "    array_dict = {key: param.data for key, param in params_dict.items()\n",
    "                    if param is not None}\n",
    "    try:\n",
    "        np.savez_compressed(path, **array_dict)\n",
    "    except (Exception, KeyboardInterrupt) as e:\n",
    "        if os.path.exists(path):\n",
    "             os.remove(path)\n",
    "        raise\n",
    "\n",
    "def load_weights(self, path):\n",
    "    npz = np.load(path)\n",
    "    params_dict = {}\n",
    "    self._flatten_params(params_dict)\n",
    "    for key, param in params_dict.items():\n",
    "            param.data = npz[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in globals():\n",
    "    import os, sys\n",
    "    sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "import dezero\n",
    "import dezero.functions as F\n",
    "from dezero import optimizers\n",
    "from dezero import DataLoader\n",
    "from dezero.models import MLP\n",
    "\n",
    "\n",
    "max_epoch = 3\n",
    "batch_size = 100\n",
    "\n",
    "train_set = dezero.datasets.MNIST(train=True)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "model = MLP((1000, 10))\n",
    "optimizer = optimizers.SGD().setup(model)\n",
    "\n",
    "if os.path.exists('my_mlp.npz'):\n",
    "    model.load_weights('my_mlp.npz')\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    sum_loss = 0\n",
    "\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "\n",
    "    print('epoch: {}, loss: {:.4f}'.format(\n",
    "        epoch + 1, sum_loss / len(train_set)))\n",
    "\n",
    "model.save_weights('my_mlp.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 54. dropout & test mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 과대적합 원인 및 해결\n",
    "* 훈련 데이터 부족 -> 데이터 증강(data augmentation)\n",
    "* 모델 표현력이 지나치게 높음 -> 가중치 감소(Weight Decay), 드롭아웃(Dropout), 배치 정규화(Batch Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dropout_ratio = 0.6\n",
    "x = np.ones(10)\n",
    "\n",
    "# dropout의 train단계에서의 behavior\n",
    "# 데이터를 흘려보낼 때마다 선별적 비활성화\n",
    "mask = np.random.rand(10) > dropout_ratio # 1, 0 masking vector\n",
    "y = x * mask \n",
    "\n",
    "# test mode에서의 행동\n",
    "# 일단 모든 뉴런을 사용하여 결과를 계산하고 그 결과를 '약화'시킨다.\n",
    "scale = 1 - dropout_ratio # 학습 시 살아남은 뉴런의 비율\n",
    "y = x * scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inverted Dropout\n",
    "> 학습단계에서 뉴런 출력조절을 미리 수행. <br/>\n",
    "테스트 시에는 아무런 동작도 하지 않음 (테스트 속도가 살짝 향상됨)<br/>\n",
    "드롭아웃 비율을 학습 시 동적으로 제어할 수 있다는 장점이 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시\n",
    "scale = 1 - dropout_ratio\n",
    "mask = np.random.rand(*x.shape) > dropout_ratio\n",
    "y = x * mask / scale\n",
    "\n",
    "# 테스트 시\n",
    "y = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(x, dropout_ratio=0.5):\n",
    "    x = as_variable(x)\n",
    "\n",
    "    if dezero.Config.train:\n",
    "        xp = cuda.get_array_module(x)\n",
    "        mask = xp.random.rand(*x.shape) > dropout_ratio\n",
    "        scale = xp.array(1.0 - dropout_ratio).astype(x.dtype)\n",
    "        y = x * mask / scale\n",
    "        return y\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "variable([2. 2. 0. 2. 0.])\n",
      "variable([1. 1. 1. 1. 1.])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dezero import test_mode\n",
    "import dezero.functions as F\n",
    "\n",
    "x = np.ones(5)\n",
    "print(x)\n",
    "\n",
    "# 학습\n",
    "y = F.dropout(x)\n",
    "print(y) # 남은 뉴런들의 출력 뻥튀기 1/(1 - dropout_ratio) 배\n",
    "\n",
    "# 추론\n",
    "with test_mode():\n",
    "    y = F.dropout(x)\n",
    "    print(y) # 아무런 동작(마스킹이나 스케일링)도 하지 않고 그대로 흘려보냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 55. CNN_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n"
     ]
    }
   ],
   "source": [
    "def get_conv_outsize(input_size, kernel_size, stride, pad):\n",
    "    return (input_size + pad * 2 - kernel_size) // stride + 1\n",
    "\n",
    "H, W = 4, 4\n",
    "KH, KW = 3, 3\n",
    "SH, SW = 1, 1\n",
    "PH, PW = 1, 1\n",
    "\n",
    "OH = get_conv_outsize(H, KH, SH, PH)\n",
    "OW = get_conv_outsize(W, KW, SW, PW)\n",
    "print(OH, OW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 56. CNN_2\n",
    "---\n",
    "### 합성곱 \n",
    "<img src = \"https://github.com/changdaeoh/DeepLearning-from-scratch/blob/main/images/56_1.png?raw=true\" width = \"60%\">\n",
    "<img src = \"https://github.com/changdaeoh/DeepLearning-from-scratch/blob/main/images/56_4.png?raw=true\" width = \"60%\">\n",
    "<img src = \"https://github.com/changdaeoh/DeepLearning-from-scratch/blob/main/images/56_5.png?raw=true\" width = \"60%\">\n",
    "\n",
    "> 필터의 가중치 데이터는 4차원 텐서(OC, IC, H, W) 형상으로 관리되며, <BR/>\n",
    "배치 데이터 역시 4차원 텐서(BS, C, H, W) 형상으로 관리됨\n",
    "\n",
    "### 풀링\n",
    "* 일반적으로(MAX, AVG 풀링 등) 학습 매개변수가 없음\n",
    "* 입출력 채널 수가 변하지 않음\n",
    "* 입력 데이터의 미세한 차이에 robust하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 57. conv2d & pooling function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### im2col\n",
    "`im2col(x, kernel_size, stride = 1, pad = 0, to_matrix = True)`\n",
    "\n",
    "<br/>\n",
    "\n",
    "입력데이터의 전개\n",
    "<img src = \"https://github.com/changdaeoh/DeepLearning-from-scratch/blob/main/images/57_1.png?raw=true\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력데이터 & 커널 전개 후 행렬곱\n",
    "<img src = \"https://github.com/changdaeoh/DeepLearning-from-scratch/blob/main/images/57_2.png?raw=true\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "def pair(x):\n",
    "    if isinstance(x, int):\n",
    "        return (x, x)\n",
    "    elif isinstance(x, tuple):\n",
    "        # assert 문의 조건식을 참으로 만들경우 정상적으로 실행됨\n",
    "        # 조건식이 거짓이 될 경우 assertion error 발생\n",
    "        assert len(x) == 2        \n",
    "        return x\n",
    "    else:\n",
    "        raise ValueError\n",
    "        \n",
    "print(pair(1))\n",
    "print(pair((1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dezero.functions as F\n",
    "\n",
    "x1 = np.random.rand(1, 3, 7, 7)\n",
    "col1 = F.im2col(x1, kernel_size = 5, stride = 1, pad = 0, to_matrix = True)\n",
    "print(col1.shape)\n",
    "\n",
    "x2 = np.random.rand(10, 3, 7, 7)\n",
    "kernel_size = (5, 5)\n",
    "stride = (1, 1)\n",
    "pad = (0, 0)\n",
    "col2 = F.im2col(x2, kernel_size, stride, pad, to_matrix = True)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/changdaeoh/DeepLearning-from-scratch/blob/main/images/im2col.jpg?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv2d function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_simple(x, W, b = None, stride = 1, pad = 0):\n",
    "    x, W = as_variable(x), as_variable(W)\n",
    "    \n",
    "    Weight = W\n",
    "    N, C, H, W = x.shape\n",
    "    OC, C, KH, KW = Weight.shape \n",
    "    SH, SW = pair(stride)\n",
    "    PH, PW = pair(pad)\n",
    "    OH = get_conv_outsize(H, KH, SH, PH)\n",
    "    OW = get_conv_outsize(W, KW, SW, PW)\n",
    "    \n",
    "    col = im2col(x, (KH, KW), stride, pad, to_matrix = True)  # flatten data\n",
    "    Weight = Weight.reshape(OC, -1).transpose()               # flatten kernel\n",
    "    t = linear(col, Weight, b)                                # flatten data에 대해 affine combination 계산\n",
    "    y = t.reshape(N, OH, OW, OC).transpose(0, 3, 1, 2)        # 첨부터 0 3 1 2순으로 reshape는 못함? \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2d layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(Layer):\n",
    "    def __init__(self, out_channels, kernel_size, stride = 1,\n",
    "                 pad = 0, nobias = False, dtype = np.float32, in_channels = None):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        self.W = Parameter(None, name = \"W\")\n",
    "        if in_channels is not None:\n",
    "            self._init_W()\n",
    "        if nobias:\n",
    "            self.b = None\n",
    "        else:\n",
    "            self.b = Parameter(np.zeros(out_channels, dtype = dtype), name = 'b')\n",
    "        \n",
    "    def _init_W(self, xp = np):\n",
    "        C, OC = self.in_channels, self.out_channels\n",
    "        KH, KW = pair(self.kernel_size)\n",
    "        scale = np.sqrt(1 / (C * KH * KW))\n",
    "        W_data = xp.random.randn(OC, C, KH, KW).astype(self.dtype) * scale\n",
    "        self.W.data = W_data\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.W.data is None:\n",
    "            self.in_channels = x.shape[1]\n",
    "            xp = cuda.get_array_module(x)\n",
    "            self._init_W(xp)\n",
    "            \n",
    "        y = F.conv2d_simple(x, self.W, self.b, self.stride, self.pad)\n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pooling function\n",
    "<img src = \"https://github.com/changdaeoh/DeepLearning-from-scratch/blob/main/images/57_5.png?raw=true\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling_simple(x, kernel_size, stride = 1, pad = 0):\n",
    "    x = as_variable(x)\n",
    "    \n",
    "    N, C, H, W = x.shape\n",
    "    KH, KW = pair(kernel_size)\n",
    "    PH, PW = pair(pad)S\n",
    "    SH, SW = pair(stride)\n",
    "    OH = get_conv_outsize(H, KH, SH, PH)\n",
    "    OW = get_conv_outsize(W, KW, SW, PW)\n",
    "    \n",
    "    col = im2col(x, kernel_size, stride, pad, to_matrix = True)\n",
    "    col = col.reshape(-1, KH * KW)\n",
    "    y = col.max(axis = 1)\n",
    "    y = y.reshape(N, OH, OW, C).transpose(0, 3, 1, 2)\n",
    "    return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
